{"./":{"url":"./","title":"前言","keywords":"","body":"正则表达式应用举例 最新版本：v1.0 更新时间：20200202 鸣谢 感谢我的老婆陈雪雪的包容理解和悉心照料，才使得我crifan有更多精力去专注技术专研和整理归纳出这些电子书和技术教程，特此鸣谢。 简介 整理正则表达式各个领域的应用，并给出实际使用案例，供参考 源码+浏览+下载 本书的各种源码、在线浏览地址、多种格式文件下载如下： Gitbook源码 crifan/regex_usage_examples: 正则表达式应用举例 如何使用此Gitbook源码去生成发布为电子书 详见：crifan/gitbook_template: demo how to use crifan gitbook template and demo 在线浏览 正则表达式应用举例 book.crifan.com 正则表达式应用举例 crifan.github.io 离线下载阅读 正则表达式应用举例 PDF 正则表达式应用举例 ePub 正则表达式应用举例 Mobi 版权说明 此电子书教程的全部内容，如无特别说明，均为本人原创和整理。其中部分内容参考自网络，均已备注了出处。如有发现侵犯您版权，请通过邮箱联系我 admin 艾特 crifan.com，我会尽快删除。谢谢合作。 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-04 18:16:29 "},"regex_usage_summary/":{"url":"regex_usage_summary/","title":"正则应用概述","keywords":"","body":"正则应用概述 如 应用广泛的超强搜索：正则表达式所说，正则的用途非常广泛，下面来整理各个领域内正则的用途和具体例子。 目的在于： 没听过正则的人：了解正则在搜索和替换等方面的功能是多么强大 听过正则但不熟悉的人：能大概了解不同领域内，正则大概是怎么使用的 需要使用正则的人：借鉴正则的写法，在需要的时候，自己写正则，满足自己的需求 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:42:55 "},"regex_usage_examples/":{"url":"regex_usage_examples/","title":"正则应用举例","keywords":"","body":"正则应用举例 下面来介绍正则表达式在不同领域的各种应用。 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:45:17 "},"regex_usage_examples/example_js.html":{"url":"regex_usage_examples/example_js.html","title":"JavaScript","keywords":"","body":"JavaScript 代码： let cowCodeRegex = new RegExp(\"/cowActivity/([^/]+)\", \"g\"); console.log(`cowCodeRegex=${cowCodeRegex}`); let foundCowCode = cowCodeRegex.exec(this.state.curUrl); ///uapp/cowActivity/12-0985/1/1522936800000 console.log(`foundCowCode=${foundCowCode}`); ///cowActivity/13-6234,13-6234 let cowCode = null; if (foundCowCode) { let inputStr = foundCowCode[0]; console.log(`inputStr=${inputStr}`); ///uapp/cowActivity/11-5953 cowCode = foundCowCode[1]; console.log(`cowCode=${cowCode}`); //11-5953 } 输出： parsePageType: currentUrl=/uapp/cowActivity/12-0985/1/1522936800000 -> page=牛只活动量 index.js?5c2a:528 cowCodeRegex=/\\/cowActivity\\/([^\\/]+)/g index.js?5c2a:530 foundCowCode=/cowActivity/12-0985,12-0985 index.js?5c2a:534 inputStr=/cowActivity/12-0985 index.js?5c2a:536 cowCode=12-0985 index.js?5c2a:540 fullTitle=牛只活动量 12-0985 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:44:16 "},"regex_usage_examples/example_python/":{"url":"regex_usage_examples/example_python/","title":"Python","keywords":"","body":"Python crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:33:40 "},"regex_usage_examples/example_python/beautifulsoup.html":{"url":"regex_usage_examples/example_python/beautifulsoup.html","title":"BeautifulSoup","keywords":"","body":"BeautifulSoup BeautifulSoup中的find和findAll的name或attr参数，支持正则写法： 代码： h1userSoupList = soup.findAll(name=\"h1\", attrs={\"class\":re.compile(r\"h1user(\\s\\w+)?\")}); 可以从html： crifan crifan 123 crifan 456 搜到列表： class=\"h1user\" class=\"h1user test1\" class=\"h1user test2\" crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:51:06 "},"regex_usage_examples/example_database/":{"url":"regex_usage_examples/example_database/","title":"数据库","keywords":"","body":"数据库 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:34:48 "},"regex_usage_examples/example_database/mongodb.html":{"url":"regex_usage_examples/example_database/mongodb.html","title":"MongoDB","keywords":"","body":"MongoDB 相关代码： if args.get('title'): filters['title'] = {'$regex': args['title'], '$options': 'i'} if args.get('unitCode'): filters['unit_code'] = {'$regex': args['unitCode'], '$options': 'i'} 其中的$regex表示搜索时，用正则搜索 -》此处含义是：去搜索title和unitCode两个字段，且i表示不区分大小写 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:47:17 "},"regex_usage_examples/example_database/mongodb_compass.html":{"url":"regex_usage_examples/example_database/mongodb_compass.html","title":"MongoDB Compass","keywords":"","body":"MongoDB Compass MongoDB Compass中想要用正则搜索字段： grading lexile: \"AD450L\" 写法是： {\"grading.lexile\": {$regex: \"AD.*\"}} 或：regex加上行首和行尾判断： {\"grading.lexile\": {$regex: \"^AD.*$\"}} 或 regex用引号引起来 {\"grading.lexile\": {\"$regex\": \"AD.*\"}} 详见： 【整理Book】主流文档型数据库：MongoDB crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:49:39 "},"regex_usage_examples/example_editor_ide/":{"url":"regex_usage_examples/example_editor_ide/","title":"编辑器和IDE","keywords":"","body":"编辑器和IDE crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 19:35:53 "},"regex_usage_examples/example_editor_ide/sublime.html":{"url":"regex_usage_examples/example_editor_ide/sublime.html","title":"Sublime","keywords":"","body":"Sublime 提取youtube网页返回的html中包含的子页面的url地址 比如，用： \"url\":\"/watch\\?v=[\\w\\-]{11}?\\\\u0026list=[\\w\\-]+\\\\u0026index=\\d+\" 可以从一堆的js中的script的值中： {\"webCommandMetadata\":{\"url\":\"/watch?v=23t1f8d2ISs\\u0026list=PLHOR8x-IicVJDAmJWZmJ-IMu1x3lTAld5\\u0026index=1\",”webPageType\" {\"webCommandMetadata\":{\"url\":\"/watch?v=au7Nkr-5MA8\\u0026list=PLHOR8x-IicVJDAmJWZmJ-IMu1x3lTAld5\\u0026index=14\",”webPageType\" 搜索出所要的内容，此处有77个符合需要的内容：1/77 点击Find，继续向下找，比如找到第14个：14/77 另外，进一步的举例： 此处，对应着页面上的其实只是希望找到66个地址就可以了： 但是此处找到77个，多出11个，则是由于： 此处的js的变量的值中，包含了不需要的额外的11个 所以此时，由于没法方便的从字符串中区别开来，不好去掉另外那11个，则只能： 想办法拿到js的变量值，然后通过转换为json，然后再去获取json对象中的值，即可准确的得到所需要的值。 所以此处，又可以接着通过正则去先得到js的变量的值： 用正则： window\\[\"ytInitialData\"\\]\\s*=\\s* ;\\s+window\\[\"ytInitialPlayerResponse\"\\] 从： window[\"ytInitialData\"] = {\"responseContext”: ... xqmOCnbELAge-VPNjlN1SqHurYg\"}}; window[\"ytInitialPlayerResponse\"] = ( 中，搜索到所要的内容： 而首尾的正则之间的内容，就是需要找的js的变量的值，是个json 对应着写个完整的正则： window\\[\"ytInitialData\"\\]\\s*=\\s*(.+?);\\s+window\\[\"ytInitialPlayerResponse\"\\] 就可以匹配到这段完整的内容了： 后续就可以通过解析json去精确获取所要的url的值了。 比如第12个url： 由此实现了： 根据自己的实际的（业务）需求，通过充分利用正则表达式，获取想要的符合特定某一规则的内容。 html中提取出浙江省的每个市到Xmind中 杭州市宁波市温州市嘉兴市湖州市绍兴市金华市衢州市舟山市台州市丽水市 希望提取出每个市 正则写法： 查找Find：(\\S+?) 替换Replace：$1\\r\\n 点击Replace All： 替换成： 忽略掉最后的，拷贝出来，即可得到我要的所有的市： 杭州市 宁波市 温州市 嘉兴市 湖州市 绍兴市 金华市 衢州市 舟山市 台州市 丽水市 -> 如此继续重复此步骤，直到把网页中的内容： 分多次，但是是批量的： 全部都整理到Xmind中： 就不用一个个拷贝，一个个粘贴了 -》 从而提高工作效率。 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 22:50:19 "},"regex_usage_examples/example_editor_ide/vscode.html":{"url":"regex_usage_examples/example_editor_ide/vscode.html","title":"VSCode","keywords":"","body":"VSCode 普通的搜索和替换 下面是一些相对普通的正则的搜索和替换的应用举例： 去除内容中多余的 lessionxxx的单词 正则： lesson\\s*\\d+\\n 从： 替换成： 语句末尾去掉感叹号 正则： !\\n \\n 从： 替换成： 高级的搜索和替换 下面是一些，相对高级一些的用法，比如： 搜索带分组 即：(xxx) 替换时带引用 即：$N N=1,2,3,... 等正则应用举例，供参考。 文章标题和链接转换为Markdown的链接 正则替换规则： (.+)\\n(http.+)\\n * [$1]($2)\\n 从： android - decompiling DEX into Java sourcecode - Stack Overflow https://stackoverflow.com/questions/1249973/decompiling-dex-into-java-sourcecode/55486175#55486175 decompiler - how to use DEXtoJar - Stack Overflow https://stackoverflow.com/questions/5257830/how-to-use-dextojar/55486507#55486507 android - Is there a way to get the source code from an APK file? - Stack Overflow https://stackoverflow.com/questions/3593420/is-there-a-way-to-get-the-source-code-from-an-apk-file/55567538#55567538 Android反编译简单实战 - 知乎 https://zhuanlan.zhihu.com/p/51260384 Android应用加固产品使用对比 - 『移动安全区』 - 吾爱破解 - LCG - LSG |安卓破解|病毒分析|破解软件|www.52pojie.cn https://www.52pojie.cn/thread-832804-1-1.html Android混淆（ProGuard）从0到1 - 简书 https://www.jianshu.com/p/1b76e4c10495 乐固加固脱壳实战 - faTe's Home http://www.holdheart.com/archives/33.html 乐固壳分析 - bamb00 - 博客园 http://www.cnblogs.com/goodhacker/p/8666217.html Android APK 反编译实践 - 简书 https://www.jianshu.com/p/9e0d1c3e342e 5分钟学会基于Xposed+DumpDex的apk快速脱壳方法 - 简书 https://www.jianshu.com/p/9d988bdddb3d 腾讯加固纯手工简易脱壳教程 - 『移动安全区』 - 吾爱破解 - LCG - LSG |安卓破解|病毒分析|破解软件|www.52pojie.cn https://www.52pojie.cn/thread-428271-1-1.html ANDROID 逆向实例（八）－ 乐固加固脱壳（2017.01） ~ and-rev https://and-rev.blogspot.com/2017/05/android-201701.html 花生日记APP邀请注册机实战（360加固脱壳） – Silkage's Blog https://blog.silkage.net/software/peanutdiary.html 如何反编译Android 的apk/dex/odex，获得源码 – 码农日记 https://www.androiddev.net/反编译android-的apk/ HangZhouCat/ReaverAPKTools: 逆向APK工具 https://github.com/HangZhouCat/ReaverAPKTools Android逆向之路---脱壳360加固 - 简书 https://www.jianshu.com/p/d24c6694fe97 26款优秀的Android逆向工程工具 - 简书 https://www.jianshu.com/p/ef0b6f75c229 Application Hardening - Mobile App Hardening | Promon https://promon.co/security-news/application-hardening/ Cydia Substrate使用手册 - 简书 https://www.jianshu.com/p/ba795ff3471a 把： 换成： * [android - decompiling DEX into Java sourcecode - Stack Overflow](https://stackoverflow.com/questions/1249973/decompiling-dex-into-java-sourcecode/55486175#55486175) * [decompiler - how to use DEXtoJar - Stack Overflow](https://stackoverflow.com/questions/5257830/how-to-use-dextojar/55486507#55486507) * [android - Is there a way to get the source code from an APK file? - Stack Overflow](https://stackoverflow.com/questions/3593420/is-there-a-way-to-get-the-source-code-from-an-apk-file/55567538#55567538) * [Android反编译简单实战 - 知乎](https://zhuanlan.zhihu.com/p/51260384) * [Android应用加固产品使用对比 - 『移动安全区』 - 吾爱破解 - LCG - LSG |安卓破解|病毒分析|破解软件|www.52pojie.cn](https://www.52pojie.cn/thread-832804-1-1.html) * [Android混淆（ProGuard）从0到1 - 简书](https://www.jianshu.com/p/1b76e4c10495) * [乐固加固脱壳实战 - faTe's Home](http://www.holdheart.com/archives/33.html) * [乐固壳分析 - bamb00 - 博客园](http://www.cnblogs.com/goodhacker/p/8666217.html) * [Android APK 反编译实践 - 简书](https://www.jianshu.com/p/9e0d1c3e342e) * [5分钟学会基于Xposed+DumpDex的apk快速脱壳方法 - 简书](https://www.jianshu.com/p/9d988bdddb3d) * [腾讯加固纯手工简易脱壳教程 - 『移动安全区』 - 吾爱破解 - LCG - LSG |安卓破解|病毒分析|破解软件|www.52pojie.cn](https://www.52pojie.cn/thread-428271-1-1.html) * [ANDROID 逆向实例（八）－ 乐固加固脱壳（2017.01） ~ and-rev](https://and-rev.blogspot.com/2017/05/android-201701.html) * [花生日记APP邀请注册机实战（360加固脱壳） – Silkage's Blog](https://blog.silkage.net/software/peanutdiary.html) * [如何反编译Android 的apk/dex/odex，获得源码 – 码农日记](https://www.androiddev.net/反编译android-的apk/) * [HangZhouCat/ReaverAPKTools: 逆向APK工具](https://github.com/HangZhouCat/ReaverAPKTools) * [Android逆向之路---脱壳360加固 - 简书](https://www.jianshu.com/p/d24c6694fe97) * [26款优秀的Android逆向工程工具 - 简书](https://www.jianshu.com/p/ef0b6f75c229) * [Application Hardening - Mobile App Hardening | Promon](https://promon.co/security-news/application-hardening/) * [Cydia Substrate使用手册 - 简书](https://www.jianshu.com/p/ba795ff3471a) 用于：放在markdown作为参考资料。 json后缀的字符串变成代码中字符串列表 正则： (\\w+)\\n \"$1\",\\n 从： booklistsJson rbrsJson latestCommentJson myCommentJson whoHasThisBookJson topicArrayJson bookFeaturesArrayJson bookFeaturesWithContentArrayJson worksCollectionArrayJson readingAgeDistributionArrayJson topReadingAgeDistributionArrayJson scoreDistributionArrayJson likeThisBookKidsAlsoLikeBookArrayJson childDataArrayJson inPagePictureArrayJson xunxiArrayJson experienceArrayJson answerArrayJson englishLevelArrayJson 变成： \"booklistsJson\", \"rbrsJson\", \"latestCommentJson\", \"myCommentJson\", \"whoHasThisBookJson\", \"topicArrayJson\", \"bookFeaturesArrayJson\", \"bookFeaturesWithContentArrayJson\", \"worksCollectionArrayJson\", \"readingAgeDistributionArrayJson\", \"topReadingAgeDistributionArrayJson\", \"scoreDistributionArrayJson\", \"likeThisBookKidsAlsoLikeBookArrayJson\", \"childDataArrayJson\", \"inPagePictureArrayJson\", \"xunxiArrayJson\", \"experienceArrayJson\", \"answerArrayJson\", \"englishLevelArrayJson\", 用于： 拷贝到代码里，用于列表变量的值： 省去：自己手动去对每一行手动去加上\"\"再控制缩进的繁琐工作了。 获取到康美通的版本历史 正则： (\\.\\d+)\\n $1 从： 相关历史版本 23.34MB最新版 康美通 4.3.0 23.34MB 安全下载 康美通 4.2.3 19.47MB 安全下载 康美通 4.2.2 19.29MB 安全下载 康美通 4.2.1 19.29MB 安全下载 康美通 4.2.0 19.18MB 安全下载 康美通 4.1.1 19.47MB 安全下载 康美通 4.1.0 19.48MB 安全下载 康美通 4.0 14.37MB 安全下载 康美通 3.2 14.22MB 安全下载 康美通 3.1 23.2MB 安全下载 康美通 3.0 23.1MB 安全下载 康美通 2.0.9 7.93MB 安全下载 康美通 2.0.8 7.3MB 安全下载 康美通 2.0.7 7.29MB 安全下载 康美通 2.0.6 7.29MB 安全下载 康美通 1.0.1 6.27MB 安全下载 康美通 1.0beta 5.86MB 安全下载 下载豌豆荚客户端 (更多历史版本)下载 康美通 历史版本年份合集 替换成： 相关历史版本 23.34MB最新版 康美通 4.3.0 23.34MB 安全下载 康美通 4.2.3 19.47MB 安全下载 康美通 4.2.2 19.29MB 安全下载 康美通 4.2.1 19.29MB 安全下载 康美通 4.2.0 19.18MB 安全下载 康美通 4.1.1 19.47MB 安全下载 康美通 4.1.0 19.48MB 安全下载 康美通 4.0 14.37MB 安全下载 康美通 3.2 14.22MB 安全下载 康美通 3.1 23.2MB 安全下载 康美通 3.0 23.1MB 安全下载 康美通 2.0.9 7.93MB 安全下载 康美通 2.0.8 7.3MB 安全下载 康美通 2.0.7 7.29MB 安全下载 康美通 2.0.6 7.29MB 安全下载 康美通 1.0.1 6.27MB 安全下载 康美通 1.0beta 5.86MB 安全下载 下载豌豆荚客户端 (更多历史版本)下载 康美通 历史版本年份合集 再去用正则： 安全下载 替换，得到我们要的： 相关历史版本： 康美通 4.3.1 23.34MB 康美通 4.3.0 23.34MB 康美通 4.2.3 19.47MB 康美通 4.2.2 19.29MB 康美通 4.2.1 19.29MB 康美通 4.2.0 19.18MB 康美通 4.1.1 19.47MB 康美通 4.1.0 19.48MB 康美通 4.0 14.37MB 康美通 3.2 14.22MB 康美通 3.1 23.2MB 康美通 3.0 23.1MB 康美通 2.0.9 7.93MB 康美通 2.0.8 7.3MB 康美通 2.0.7 7.29MB 康美通 2.0.6 7.29MB 康美通 1.0.1 6.27MB 康美通 1.0beta 5.86MB 去掉srt字幕中font size 正则： ([^<>/]+) $1 从： 替换成： crifan电子书中链接替换 对于我的电子书的说明： https://github.com/crifan/crifan_ebook_readme 的markdown源码： 想要把其中的地址： https://crifan.github.io/xxx/website 替换为： https://book.crifan.com/books/xxx/website/ 比如： https://crifan.github.io/program_code_style/website 替换成： https://book.crifan.com/books/program_code_style/website/ 用正则： https?://crifan.github.io/(\\w+)/website/? https://book.crifan.com/books/$1/website/ 实现从： 替换成： 将Chrome中拷贝出来的cookie处理成代码中要的dict Chrome中拷贝出来的cookie是： welcomeflash=20050606_107001; zzpaneluin=; zzpanelkey=; pgv_pvi=7640393728; pgv_si=s3147298816; pgv_pvid=3951804270; pgv_info=ssid=s7487670374; ptisp=ctc; ptui_loginuin=2539619267; pt2gguin=o2539619267; uin=o2539619267; skey=@nDTkOJm1m; RK=Ye5Jmtb0ly; ptcz=3b6806bf7cddc375bc2d23b04ff9c366b47fac808b9256322ad69a23f2dc580f; p_uin=o2539619267; pt4_token=aC5vGfNAA2M3fS7ngcAHdXoiCvqwrAGcEuL54gs63oE_; p_skey=kSC7q75Gk93gLlo*mRMg*h2m3iYUuubjQqVBIgEMi*o_; Loading=Yes 最后加上分号： welcomeflash=20050606_107001; zzpaneluin=; zzpanelkey=; pgv_pvi=7640393728; pgv_si=s3147298816; pgv_pvid=3951804270; pgv_info=ssid=s7487670374; ptisp=ctc; ptui_loginuin=2539619267; pt2gguin=o2539619267; uin=o2539619267; skey=@nDTkOJm1m; RK=Ye5Jmtb0ly; ptcz=3b6806bf7cddc375bc2d23b04ff9c366b47fac808b9256322ad69a23f2dc580f; p_uin=o2539619267; pt4_token=aC5vGfNAA2M3fS7ngcAHdXoiCvqwrAGcEuL54gs63oE_; p_skey=kSC7q75Gk93gLlo*mRMg*h2m3iYUuubjQqVBIgEMi*o_; Loading=Yes; 再去用正则： (\\w+)=([^,^=]*); ? \"$1\": \"$2\",\\n 替换： 成自己要的dict的内容： 中间有个特殊的，自己手动改一下即可： \"welcomeflash\": \"20050606_107001\", \"zzpaneluin\": \"\", \"zzpanelkey\": \"\", \"pgv_pvi\": \"7640393728\", \"pgv_si\": \"s3147298816\", \"pgv_pvid\": \"3951804270\", \"pgv_info\": \"ssid=s7487670374\", \"ptisp\": \"ctc\", \"ptui_loginuin\": \"2539619267\", \"pt2gguin\": \"o2539619267\", \"uin\": \"o2539619267\", \"skey\": \"@nDTkOJm1m\", \"RK\": \"Ye5Jmtb0ly\", \"ptcz\": \"3b6806bf7cddc375bc2d23b04ff9c366b47fac808b9256322ad69a23f2dc580f\", \"p_uin\": \"o2539619267\", \"pt4_token\": \"aC5vGfNAA2M3fS7ngcAHdXoiCvqwrAGcEuL54gs63oE_\", \"p_skey\": \"kSC7q75Gk93gLlo*mRMg*h2m3iYUuubjQqVBIgEMi*o_\", \"Loading\": \"Yes;\", 粘贴到代码中即可使用了： 处理得到城市名称 除了： 【整理】中国常见的城市的名字 以及： 对于： https://en.wikipedia.org/wiki/List_of_urban_areas_by_population 中的城市名，用正则： \\[\\d+\\] 去除掉[数字] 从： 替换成： 以及继续用： \\(([\\w\\s]+)\\)$ $1 把(xxx)中的xxx放到下一行 从： 替换成： 当然，也注意到了，没有匹配到： Nagoya (Chūkyō) 是因为里面有unicode的字符，由于数量不多，手动处理即可。 再去用： –([\\w\\s]+) \\n$1 把xxx-yyy中的yyy放到下一行 替换成： 以及，用： \\s*\\(.+\\)$ 把xxx (yyy)中的空格(yyy)去掉： 替换成： 再继续，用： ^\\s \\n 可以找到： 有哪些单词在行首有多余的空格（后续可以再去删除掉）： ![vscode_remove_start_empty.png) 提取mp3文件名和mp3链接地址 正则： ^[^\\r\\n]+href=\"(\\w+\\](../../assets/img/vscode_remove_start_empty.png) ## 提取mp3文件名和mp3链接地址 正则： ```bash ^[^\\r\\n]+href=\"(\\w+\\.mp3)\"[^\\r\\n]+$ $1 把： e10d3a.mp3 2015-09-23 09:10 9.3M e10d3b.mp3 2015-09-23 09:10 7.0M e10d5a.mp3 2015-09-23 09:11 54M 替换为： e10d3a.mp3 e10d3b.mp3 e10d5a.mp3 再进一步： 用正则： ^[^\\r\\n]+href=\"(\\w+\\.mp3)\"[^\\r\\n]+$ http://media.talkbank.org/CHILDES/Biling/Singapore/$1 从： e10d3a.mp3 2015-09-23 09:10 9.3M e10d3b.mp3 2015-09-23 09:10 7.0M e10d5a.mp3 2015-09-23 09:11 54M 替换和提取出： http://media.talkbank.org/CHILDES/Biling/Singapore/e10d3a.mp3 http://media.talkbank.org/CHILDES/Biling/Singapore/e10d3b.mp3 http://media.talkbank.org/CHILDES/Biling/Singapore/e10d5a.mp3 详见： 【已解决】VSCode中如何使用正则表达式去替换且被替换中使用分组group 去除掉csv中多余的=\"xxx\" 客户给的一个数据文件csv格式的，但是内部内容中发现有多余的 =\"xxx\"，应该改为xxx才对。 所以用VSCode去替换，用正则： =\"(.+?)” $1 实现了，把 =\"7xxx1\"： 替换成 7xxx1： 即可。 给文章段落增加换行 用正则： \\n(\\d.) \\n\\n$1 把： ...互。 1.字节跳动 ...说过。 2.陆奇给年轻人的话 ... 8.网易 丁磊 ... 变成： ...互。 1.字节跳动 ...说过。 2.陆奇给年轻人的话 ... 8.网易 丁磊 ... 把url中查询参数换成代码中字典参数 用正则： dt=([^&]+)&? \"dt\": \"$1\",\\n 把： dt=at&dt=bd&dt=ex&dt=ld&dt=md&dt=qca&dt=rw&dt=rm&dt=ss&dt=t 替换成： \"dt\": \"at\", \"dt\": \"bd\", \"dt\": \"ex\", \"dt\": \"ld\", \"dt\": \"md\", \"dt\": \"qca\", \"dt\": \"rw\", \"dt\": \"rm\", \"dt\": \"ss\", \"dt\": \"t\", 用于后续放到代码中使用： 把每个词都加上引号，用于放代码中用 用正则： (.+) \"$1\", 从输入： 更新公告 签到奖励 离线经验 在线奖励 等级礼包 资源找回 活动时间 活动内容 累计充值 变成： \"更新公告\", \"签到奖励\", \"离线经验\", \"在线奖励\", \"等级礼包\", \"资源找回\", \"活动时间\", \"活动内容\", \"累计充值\", 用于拷贝到代码中使用： 提取104协议示例数据，并格式化成java代码中字符串数组 从： EB90EB90(端口号:21站0)[2020/1/6 18:18:58] 发送： 68 04 07 00 00 00 EB90EB90(端口号:21站5)[2020/1/6 18:19:07] 接收： 68 12 E6 B7 00 00 0F 81 05 00 05 00 01 0C 00 95 42 03 00 00 EB90EB90(端口号:21站5)[2020/1/6 18:19:07] 发送： 68 04 01 00 E6 B7 EB90EB90(端口号:21站5)[2020/1/6 18:19:12] 接收： 68 14 E8 B7 00 00 01 87 14 00 05 00 01 00 00 01 01 01 00 00 00 01 EB90EB90(端口号:21站5)[2020/1/6 18:19:12] 发送： 68 04 01 00 E8 B7 EB90EB90(端口号:21站5)[2020/1/6 18:19:17] 接收： 68 59 EA B7 00 00 15 A6 14 00 05 00 01 07 00 02 00 00 00 00 00 EC 5C CB 5C DF 5C 45 00 01 00 FE FF 7C 00 94 02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 86 13 00 00 02 00 00 00 00 00 FE FF 00 00 00 00 87 00 00 00 00 00 02 00 00 00 00 00 ... EB90EB90(端口号:21站5)[2020/1/6 23:08:55] 发送： 68 04 01 00 12 D3 EB90EB90(端口号:21站5)[2020/1/6 23:09:00] 接收： 68 59 14 D3 00 00 15 A6 14 00 05 00 01 07 00 02 00 00 00 00 00 BC 5D 88 5D A7 5D 44 00 01 00 FE FF 7C 00 84 02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 88 13 00 00 02 00 00 00 00 00 FE FF 00 00 00 00 B6 00 00 00 00 00 02 00 00 00 00 00 EB90EB90(端口号:21站5)[2020/1/6 23:09:06] 接收： 68 12 16 D3 00 00 0F 81 05 00 05 00 01 0C 00 B6 42 03 00 00 EB90EB90(端口号:21站5)[2020/1/6 23:09:06] 发送： 68 04 01 00 16 D3 提取出：接收：的下一行的一连串数字 （1）先 去除 发送的部分 正则： ^EB.+发送：\\n(^.+)$\\n 替换成： （2）再去把接收部分中数字提取出来 从： EB90EB90(端口号:21站5)[2020/1/6 18:19:07] 接收： 68 12 E6 B7 00 00 0F 81 05 00 05 00 01 0C 00 95 42 03 00 00 EB90EB90(端口号:21站5)[2020/1/6 18:19:12] 接收： 68 14 E8 B7 00 00 01 87 14 00 05 00 01 00 00 01 01 01 00 00 00 01 ... EB90EB90(端口号:21站5)[2020/1/6 23:08:55] 接收： 68 14 12 D3 00 00 01 87 14 00 05 00 01 00 00 01 01 01 00 00 00 01 EB90EB90(端口号:21站5)[2020/1/6 23:09:00] 接收： 68 59 14 D3 00 00 15 A6 14 00 05 00 01 07 00 02 00 00 00 00 00 BC 5D 88 5D A7 5D 44 00 01 00 FE FF 7C 00 84 02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 88 13 00 00 02 00 00 00 00 00 FE FF 00 00 00 00 B6 00 00 00 00 00 02 00 00 00 00 00 EB90EB90(端口号:21站5)[2020/1/6 23:09:06] 接收： 68 12 16 D3 00 00 0F 81 05 00 05 00 01 0C 00 B6 42 03 00 00 用正则： ^EB.+接收：\\n(^.+)$ $1 把： 替换成： 得到每一行的数字： 68 12 E6 B7 00 00 0F 81 05 00 05 00 01 0C 00 95 42 03 00 00 68 14 E8 B7 00 00 01 87 14 00 05 00 01 00 00 01 01 01 00 00 00 01 68 59 EA B7 00 00 15 A6 14 00 05 00 01 07 00 02 00 00 00 00 00 EC 5C CB 5C DF 5C 45 00 01 00 FE FF 7C 00 94 02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 86 13 00 00 02 00 00 00 00 00 FE FF 00 00 00 00 87 00 00 00 00 00 02 00 00 00 00 00 ... 68 12 16 D3 00 00 0F 81 05 00 05 00 01 0C 00 B6 42 03 00 00 （3）再去变成java字符串数组，即给每一行加上前后双引号 用正则： ^(.+)$ \"$1\", 把： 变成： \"68 12 E6 B7 00 00 0F 81 05 00 05 00 01 0C 00 95 42 03 00 00 \", \"68 14 E8 B7 00 00 01 87 14 00 05 00 01 00 00 01 01 01 00 00 00 01 \", \"68 59 EA B7 00 00 15 A6 14 00 05 00 01 07 00 02 00 00 00 00 00 EC 5C CB 5C DF 5C 45 00 01 00 FE FF 7C 00 94 02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 86 13 00 00 02 00 00 00 00 00 FE FF 00 00 00 00 87 00 00 00 00 00 02 00 00 00 00 00 \", \"68 12 EC B7 00 00 0F 81 05 00 05 00 01 0C 00 95 42 03 00 00 \", ... \"68 12 16 D3 00 00 0F 81 05 00 05 00 01 0C 00 B6 42 03 00 00 \", 用于粘贴到代码中使用： ->从而把： 繁琐的，手工的，从原始文件中拷贝和粘贴的重复劳动， 快捷的，自动的，完成，且更准确，不会出现手动操作的失误。 填充Markdown中图片文件名 此处正在写教程期间，正好有个需求：为了避免和消除Markdown中的，关于图片的文件名即image的alt的text是空的警告： 然后正好用正则，去自动填充此处image的alt的text，即图片的文件名 用正则： !\\[\\]\\(\\.\\./\\.\\./assets/img/([^/]+)\\.(\\w{3})\\) ![$1](../../assets/img/$1.$2) 把： ![sublime_2nd_findall](../../assets/img/sublime_2nd_findall.png) ![sublime_2nd_replaced](../../assets/img/sublime_2nd_replaced.png) ![regex_all_city_to_xmind](../../assets/img/regex_all_city_to_xmind.png) 变成： ![sublime_2nd_findall](../../assets/img/sublime_2nd_findall.png) ![sublime_2nd_replaced](../../assets/img/sublime_2nd_replaced.png) ![regex_all_city_to_xmind](../../assets/img/regex_all_city_to_xmind.png) 即可自动填充image的alt的text，消除Markdown中的警告了。 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 22:54:11 "},"appendix/":{"url":"appendix/","title":"附录","keywords":"","body":"附录 下面列出相关参考资料。 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 18:46:07 "},"appendix/reference.html":{"url":"appendix/reference.html","title":"参考资料","keywords":"","body":"参考资料 【教程】BeautifulSoup中使用正则表达式去搜索多种可能的关键字 – 在路上 【已解决】VSCode中如何使用正则表达式去替换且被替换中使用分组group 【整理】中国常见的城市的名字 crifan.com，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-02-02 22:49:25 "}}